# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

```bash
# Install dependencies
uv sync

# Run development server
uv run python manage.py runserver

# Run migrations
uv run python manage.py migrate

# Run all tests
uv run pytest

# Run tests for a specific app
uv run pytest apps/sessions/

# Run pipeline integration tests (requires GEMINI_API_KEY)
uv run pytest pipeline/ -m integration

# Format and lint
uv run ruff format .
uv run ruff check .

# Type checking
uv run mypy .

# Seed initial data
uv run python manage.py seed_dishes
uv run python manage.py seed_knowledge_base

# Start Pub/Sub emulator (separate terminal)
gcloud beta emulators pubsub start --project=local-dev

# Run pipeline worker locally (separate terminal)
uv run python pipeline/worker.py --local
```

## Architecture

### Request â†’ Response (Web)
Browser (Django templates + HTMX) â†’ Django + DRF (Cloud Run) â†’ Cloud SQL (PostgreSQL)

### Async AI Pipeline (the core product)
Video upload â†’ GCS â†’ Pub/Sub message â†’ Cloud Run Job triggers 4-stage pipeline:
1. **Stage 1 â€” Video Analysis** (`pipeline/stages/video_analysis.py`): CHEF-VL dual-agent pattern using Gemini 3 Flash Preview. Agent A extracts cooking events + timestamps; Agent B tracks environment state (heat, ingredient state). Synthesis agent identifies the single most important `key_moment_timestamp`.
2. **Stage 2 â€” RAG** (`pipeline/stages/rag.py`): Vertex AI Vector Search over cooking principles knowledge base + past session summaries from `LearnerState`.
3. **Stage 3 â€” Coaching Script** (`pipeline/stages/coaching_script.py`): Gemini 3 Flash Preview generates `coaching_text` (4-section structured JSON) and `narration_script` (2-part: `part1`, fixed `pivot` line, `part2` synced to key moment clip).
4. **Stage 4 â€” Video Production** (`pipeline/stages/video_production.py`): Cloud TTS synthesizes audio for part1 + part2. FFmpeg extracts 15s clip at `key_moment_seconds`, composes `intro_segment + key_moment_clip + outro.mp3` â†’ `coaching_video.mp4` â†’ GCS.

After pipeline completes, two chat messages are auto-created: raw video in "Cooking Videos" room, coaching text + video URL in "Coaching" room.

### Django App Structure (`apps/`)
- **`users/`** â€” `User` (extends AbstractUser, has `learner_profile` JSONField), `LearnerState` (longitudinal skill tracking: `skills_acquired`, `skills_developing`, `recurring_mistakes`, `learning_velocity`)
- **`dishes/`** â€” `Dish` (slug, principles JSONField, `transferable_to`), `UserDishProgress`
- **`sessions/`** â€” `Session` (the central model: holds `raw_video_url`, `video_analysis` JSONField, `coaching_text` JSONField, `narration_script` JSONField, `coaching_video_url`, `status` enum)
- **`chat/`** â€” `ChatRoom` (two types: `cooking_videos`, `coaching`), `Message` (sender: user/ai/system, has `text`, `video_url`, `metadata` JSONField)

### Settings layout
`config/settings/base.py` â†’ `local.py` / `production.py`

### Key design decisions baked in
- **Japanese only** (`ja-JP`): All AI prompts, TTS voice (`ja-JP-Neural2-B`), coaching text in Japanese.
- **Gemini 3 Flash Preview** for all AI tasks (video analysis + coaching script generation). Use `GEMINI_MODEL=gemini-3-flash-preview`.
- **No Django admin for chat**: Messages are system-generated by the pipeline. Only the coaching chat room supports user replies (follow-up Q&A).
- **Coaching video pivot line is fixed**: `"å‹•ç”»ã‚’ä½¿ã£ã¦ãã®ãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†"` â€” always the exact string in `narration_script.pivot`.
- **Session limit**: max 3 sessions per dish per user (`session_number` âˆˆ {1, 2, 3}).
- **Dish principles drive RAG queries**: `Dish.principles` (list of principle slugs) are combined with `video_analysis.diagnosis` as the Vector Search query in Stage 2.
- **Coaching text format** (4 sections with emoji headers): `ğŸ³ ä»Šå›ã®å•é¡Œç‚¹` / `ğŸ³ {N}å›ç›®ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§èº«ã«ã¤ã‘ã‚‹ã¹ãã‚¹ã‚­ãƒ«` / `æ¬¡å›è©¦ã™ã“ã¨` / `âœ… æˆåŠŸã®ã‚µã‚¤ãƒ³`.

### Knowledge Base (`knowledge_base/`)
Cooking principles stored as Markdown files in `knowledge_base/principles/`. `knowledge_base/ingest.py` embeds them and uploads to Vertex AI Vector Search. The 3 starter dishes (ãƒãƒ£ãƒ¼ãƒãƒ³, ãƒ“ãƒ¼ãƒ•ã‚¹ãƒ†ãƒ¼ã‚­, ãƒãƒ¢ãƒ‰ãƒ¼ãƒ­) each encode transferable principles (e.g., fried rice â†’ moisture control â†’ also applies to minestrone/ratatouille).

### Coaching video structure (confirmed)
```
[Part 1: timelapse + TTS narration]   session intro + core principle + diagnosis
[Pivot]                                "å‹•ç”»ã‚’ä½¿ã£ã¦ãã®ãƒã‚¤ãƒ³ãƒˆã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†"
[Part 2: user's ~15s clip + TTS]       narration synced to key_moment clip
[Outro]                                outro.mp3 (static/audio/outro.mp3)
```
